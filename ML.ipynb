{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82133f0d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97174787",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from ows import ows\n",
    "from ows import fouriertransform as mathft\n",
    "from astropy.io import fits\n",
    "from astropy.visualization import SqrtStretch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b86c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b31b6c1",
   "metadata": {},
   "source": [
    "# Assemble dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e434251",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 9999\n",
    "\n",
    "# train_DwDx = np.zeros((n,128,128))\n",
    "# train_DwDy = np.zeros((n,128,128))\n",
    "train_Dw = np.zeros((n,128,128,2))\n",
    "#train_Dw = np.zeros((n,128,128))\n",
    "train_lightfield = np.zeros((n,128,128))\n",
    "train_psf = np.zeros((n,128,128))\n",
    "print(train_Dw.shape)\n",
    "filename0 = \"data/DwDx_\"\n",
    "filename1 = \"data/DwDy_\"\n",
    "filename2 = \"data/lightfield_\"\n",
    "filename3 = \"data/psf_\"\n",
    "\n",
    "status = 0\n",
    "for i in range(0,n):\n",
    "    train_Dw[i,:,:,0] = ows.pixel_adder(np.array(fits.getdata(filename0+str(i)+\".fits\")), scale_factor = [8,8], final_shape = None)/np.pi\n",
    "    #train_Dw[i,:,:,1] = np.array(fits.getdata(filename0+str(i)+\".fits\"))\n",
    "    train_Dw[i,:,:,1] = ows.pixel_adder(np.array(fits.getdata(filename1+str(i)+\".fits\")), scale_factor = [8,8], final_shape = None)/np.pi\n",
    "    #train_Dw[i,:,:,1] = np.array(fits.getdata(filename1+str(i)+\".fits\"))\n",
    "\n",
    "    # train_lightfield[:,:,i] = ows.pixel_adder(np.array(fits.getdata(filename2+str(i)+\".fits\"),[1/8,1/8])\n",
    "    train_lightfield[i,:,:] = np.array(fits.getdata(filename2+str(i)+\".fits\"))\n",
    "    # train_psf[:,:,i] = ows.pixel_adder(np.array(fits.getdata(filename3+str(i)+\".fits\")),[1/8,1/8])\n",
    "    train_psf[i,:,:] = ows.normalize(np.array(fits.getdata(filename3+str(i)+\".fits\")))\n",
    "    if 100*i//n == status*10:\n",
    "        print('Loading training set: ',status*10,'% done')\n",
    "        status += 1\n",
    "print('Loading training set: ',100,'% done')\n",
    "#np.savez(\"data/train_DwDx.npz\", train_DwDy)\n",
    "#np.savez(\"data/train_DwDy.npz\", train_DwDy)\n",
    "np.savez(\"data/train_Dw.npz\", train_Dw)\n",
    "np.savez(\"data/train_lightfield.npz\", train_lightfield)\n",
    "np.savez(\"data/train_psf.npz\", train_psf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7066da80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del train_DwDx\n",
    "# del train_DwDy\n",
    "#del train_lightfield\n",
    "rng = np.random.default_rng(seed=None)\n",
    "n =9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41b8795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "rng = np.random.default_rng(n)\n",
    "temp = np.load(\"data/train_Dw.npz\")[\"arr_0\"]\n",
    "n = temp.shape[0]\n",
    "k = 0.6 \n",
    "train_id = np.zeros(n,np.bool)\n",
    "\n",
    "train_id[rng.choice(n,int(k*n),replace=False)] = True\n",
    "\n",
    "\n",
    "x_train = temp[train_id,:,:,:]\n",
    "x_val = temp[~train_id,:,:,:]\n",
    "# y_train = temp[train_id,:,:]\n",
    "# y_val = temp[~train_id,:,:]\n",
    "\n",
    "\n",
    "temp = np.load(\"data/train_psf.npz\")[\"arr_0\"]\n",
    "\n",
    "y_train = temp[train_id,:,:]\n",
    "y_val = temp[~train_id,:,:]\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "plt.close(1)\n",
    "plt.figure(1)\n",
    "plt.imshow(x_train[4,:,:,1])\n",
    "plt.show()\n",
    "\n",
    "print(x_val.shape,x_train.shape)\n",
    "print(y_val.shape,y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3174738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28a5ae00",
   "metadata": {},
   "source": [
    "# Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9669391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unet\n",
    "model = unet.build_unet(input_shape=(128,128,2), n_channels_out=1)\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51578db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau \n",
    "weight_path=\"{}_weights.best.weights.h5\".format('cxr_reg') \n",
    " \n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1,  \n",
    "                             save_best_only=True, mode='min', save_weights_only = True) \n",
    " \n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=3, \n",
    "                                   verbose=1, mode='min', epsilon=0.05, cooldown=2, min_lr=1e-6) \n",
    " \n",
    "early = EarlyStopping(monitor=\"val_loss\",  mode=\"min\", patience=15) # probably needs to be more patient, but kaggle time is limited \n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]\n",
    "\n",
    "from IPython.display import clear_output \n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.optimizers import SGD \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import roc_curve, auc \n",
    "model.compile(optimizer=SGD(learning_rate=0.001, momentum=0.9), loss=[unet.mse_loss], metrics = [unet.dice_coef, 'binary_accuracy',\"AUC\" ]) \n",
    "#images, mask = images/255, (mask>127).astype(np.float32) \n",
    "                                                            \n",
    "train_vol = x_train\n",
    "\n",
    "validation_vol = x_val\n",
    "train_seg = y_train\n",
    "validation_seg = y_val\n",
    "\n",
    "print(train_seg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34bfd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = model.fit(x = train_vol,y = train_seg,batch_size = 8,epochs = 100,validation_data =(validation_vol,validation_seg) , callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5195bb",
   "metadata": {},
   "source": [
    "# Training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a156ef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\n",
    "ax1.plot(loss_history.history['loss'], '-', label = 'Loss')\n",
    "ax1.plot(loss_history.history['val_loss'], '-', label = 'Validation Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(100*np.array(loss_history.history['binary_accuracy']), '-', label = 'Accuracy')\n",
    "ax2.plot(100*np.array(loss_history.history['val_binary_accuracy']), '-',label = 'Validation Accuracy')\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb2415e",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fe092d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DwDx = ows.pixel_adder(np.array(fits.getdata(\"data/DwDx_9999.fits\")), scale_factor = [8,8], final_shape = None)\n",
    "DwDy = ows.pixel_adder(np.array(fits.getdata(\"data/DwDy_9999.fits\")), scale_factor = [8,8], final_shape = None)\n",
    "psf = np.array(fits.getdata(\"data/psf_9999.fits\"))\n",
    "#Dw = (DwDx**2 + DwDx**2)**(1/2)\n",
    "Dw = np.zeros((128,128,2))\n",
    "\n",
    "Dw[:,:,0] = DwDx\n",
    "Dw[:,:,1] = DwDy\n",
    "\n",
    "im = np.expand_dims(Dw, axis=0)\n",
    "\n",
    "predictions = model(im)\n",
    "print(predictions.shape)\n",
    "\n",
    "\n",
    "plt.close(2)\n",
    "plt.figure(2)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(predictions[0,:,:])\n",
    "plt.title(\"inference\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(psf[:,:])\n",
    "plt.title(\"True image\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
